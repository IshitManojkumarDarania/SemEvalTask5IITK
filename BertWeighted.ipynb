{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RouvniB-_3L-",
    "outputId": "e73570e5-7e6f-4ecb-df62-5f420ace406b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at nlpaueb/legal-bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "\n",
    "# Load Legal BERT model\n",
    "model_name = \"nlpaueb/legal-bert-base-uncased\"\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "fmImMNhtGm9a"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "E_PagZSyCbEk"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "8CD4lVKNCd5n"
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('train31.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "q-Hl1pRmDnYH"
   },
   "outputs": [],
   "source": [
    "df.fillna(' ',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "QdOr9KXiD5CS"
   },
   "outputs": [],
   "source": [
    "text=[]\n",
    "labels=[]\n",
    "for i in range(len(df)):\n",
    "  temp=df['question'][i]+df['answer'][i]+df['expl'][i]\n",
    "  text.append(temp)\n",
    "  labels.append(df['label'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "yhnedq4UyjYW"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(labels), y=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rzpN5WR_ytxD",
    "outputId": "18407248-c9b9-45c5-bb3a-9abf19821226"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.65940594 2.06832298]\n"
     ]
    }
   ],
   "source": [
    "print(class_weights)\n",
    "class_weight_dict = {0: class_weights[0], 1: 1.1*class_weights[1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "B-QNG-mWH8sz"
   },
   "outputs": [],
   "source": [
    "tokenized_input = tokenizer(text, return_tensors=\"tf\", padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "yxf8V1KxH-5U"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "input_ids = tokenized_input['input_ids']\n",
    "attention_mask = tokenized_input['attention_mask']\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class F1Score(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='f1_score', **kwargs):\n",
    "        super(F1Score, self).__init__(name=name, **kwargs)\n",
    "        self.precision = self.add_weight(name='precision', initializer='zeros')\n",
    "        self.recall = self.add_weight(name='recall', initializer='zeros')\n",
    "        self.f1 = self.add_weight(name='f1', initializer='zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.keras.backend.cast(y_true, 'float')\n",
    "        y_pred = tf.keras.backend.cast(tf.keras.backend.round(y_pred), 'float')\n",
    "\n",
    "        true_positives = tf.keras.backend.sum(tf.keras.backend.cast(y_true * y_pred, 'float'))\n",
    "        predicted_positives = tf.keras.backend.sum(y_pred)\n",
    "        possible_positives = tf.keras.backend.sum(y_true)\n",
    "\n",
    "        precision = true_positives / (predicted_positives + tf.keras.backend.epsilon())\n",
    "        recall = true_positives / (possible_positives + tf.keras.backend.epsilon())\n",
    "        f1 = 2 * (precision * recall) / (precision + recall + tf.keras.backend.epsilon())\n",
    "\n",
    "        self.precision.assign_add(precision)\n",
    "        self.recall.assign_add(recall)\n",
    "        self.f1.assign_add(f1)\n",
    "\n",
    "    def result(self):\n",
    "        return self.f1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ult3eBqyz3-j"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer=optimizer, loss=loss_fn, metrics=['accuracy'])\n",
    "epochs = 1\n",
    "batch_size = 2\n",
    "model.trainable = True\n",
    "\n",
    "# optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)\n",
    "# loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "# f1_metric = F1Score()\n",
    "# model.compile(optimizer=optimizer, loss=loss_fn, metrics=[f1_metric])\n",
    "# epochs = 1\n",
    "# batch_size = 2\n",
    "# model.trainable = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CvtlXTFm0Dtf",
    "outputId": "f820fffc-a64a-4759-8828-2090e4415a1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch: 1, Class Weights: {0: 0.6594059405940594, 1: 2.2751552795031054}\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "Epoch: 1, Batch: 1, Loss: [0.5299914479255676, 0.5]\n",
      "Predictions: [0 1]\n",
      "Epoch: 1, Batch: 2, Class Weights: {0: 0.6594059405940594, 1: 2.2751552795031054}\n",
      "1/1 [==============================] - 1s 552ms/step\n",
      "Epoch: 1, Batch: 2, Loss: [1.4694968461990356, 0.5]\n",
      "Predictions: [0 0]\n",
      "Epoch: 1, Batch: 3, Class Weights: {0: 0.6594059405940594, 1: 2.2751552795031054}\n",
      "1/1 [==============================] - 1s 565ms/step\n",
      "Epoch: 1, Batch: 3, Loss: [1.0999786853790283, 0.5]\n",
      "Predictions: [0 0]\n",
      "Epoch: 1, Batch: 4, Class Weights: {0: 0.6594059405940594, 1: 2.2751552795031054}\n",
      "1/1 [==============================] - 1s 583ms/step\n",
      "Epoch: 1, Batch: 4, Loss: [0.4904484748840332, 0.0]\n",
      "Predictions: [0 0]\n",
      "Epoch: 1, Batch: 5, Class Weights: {0: 0.6594059405940594, 1: 2.2751552795031054}\n",
      "1/1 [==============================] - 1s 555ms/step\n",
      "Epoch: 1, Batch: 5, Loss: [1.2287830114364624, 0.5]\n",
      "Predictions: [1 1]\n",
      "Epoch: 1, Batch: 6, Class Weights: {0: 0.6594059405940594, 1: 2.2751552795031054}\n",
      "1/1 [==============================] - 1s 574ms/step\n",
      "Epoch: 1, Batch: 6, Loss: [0.47171688079833984, 0.5]\n",
      "Predictions: [1 1]\n",
      "Epoch: 1, Batch: 7, Class Weights: {0: 0.6594059405940594, 1: 2.2751552795031054}\n",
      "1/1 [==============================] - 1s 569ms/step\n",
      "Epoch: 1, Batch: 7, Loss: [0.8026072382926941, 1.0]\n",
      "Predictions: [1 1]\n",
      "Epoch: 1, Batch: 8, Class Weights: {0: 0.6594059405940594, 1: 2.2751552795031054}\n",
      "1/1 [==============================] - 1s 594ms/step\n",
      "Epoch: 1, Batch: 8, Loss: [0.5372351408004761, 0.0]\n",
      "Predictions: [1 1]\n",
      "Epoch: 1, Batch: 9, Class Weights: {0: 0.6594059405940594, 1: 2.2751552795031054}\n",
      "1/1 [==============================] - 1s 543ms/step\n",
      "Epoch: 1, Batch: 9, Loss: [1.0397554636001587, 0.5]\n",
      "Predictions: [1 1]\n",
      "Epoch: 1, Batch: 10, Class Weights: {0: 0.6594059405940594, 1: 2.2751552795031054}\n",
      "1/1 [==============================] - 1s 574ms/step\n",
      "Epoch: 1, Batch: 10, Loss: [0.49588173627853394, 0.0]\n",
      "Predictions: [1 1]\n",
      "Epoch: 1, Batch: 11, Class Weights: {0: 0.6594059405940594, 1: 2.2751552795031054}\n",
      "1/1 [==============================] - 1s 544ms/step\n",
      "Epoch: 1, Batch: 11, Loss: [0.8131542205810547, 1.0]\n",
      "Predictions: [1 1]\n",
      "Epoch: 1, Batch: 12, Class Weights: {0: 0.6594059405940594, 1: 2.2751552795031054}\n",
      "1/1 [==============================] - 1s 513ms/step\n",
      "Epoch: 1, Batch: 12, Loss: [0.5719485878944397, 0.0]\n",
      "Predictions: [1 1]\n",
      "Epoch: 1, Batch: 13, Class Weights: {0: 0.6594059405940594, 1: 2.2751552795031054}\n",
      "1/1 [==============================] - 1s 514ms/step\n",
      "Epoch: 1, Batch: 13, Loss: [0.879935622215271, 0.5]\n",
      "Predictions: [1 1]\n",
      "Epoch: 1, Batch: 14, Class Weights: {0: 0.6594059405940594, 1: 2.2751552795031054}\n",
      "1/1 [==============================] - 1s 516ms/step\n",
      "Epoch: 1, Batch: 14, Loss: [0.607282280921936, 0.0]\n",
      "Predictions: [1 1]\n",
      "Epoch: 1, Batch: 15, Class Weights: {0: 0.6594059405940594, 1: 2.2751552795031054}\n",
      "1/1 [==============================] - 1s 514ms/step\n",
      "Epoch: 1, Batch: 15, Loss: [0.5023201107978821, 0.0]\n",
      "Predictions: [1 1]\n",
      "Epoch: 1, Batch: 16, Class Weights: {0: 0.6594059405940594, 1: 2.2751552795031054}\n",
      "1/1 [==============================] - 1s 519ms/step\n",
      "Epoch: 1, Batch: 16, Loss: [0.9337285757064819, 0.5]\n",
      "Predictions: [1 1]\n",
      "Epoch: 1, Batch: 17, Class Weights: {0: 0.6594059405940594, 1: 2.2751552795031054}\n",
      "1/1 [==============================] - 1s 519ms/step\n",
      "Epoch: 1, Batch: 17, Loss: [1.1098798513412476, 0.0]\n",
      "Predictions: [1 1]\n",
      "Epoch: 1, Batch: 18, Class Weights: {0: 0.6594059405940594, 1: 2.2751552795031054}\n",
      "1/1 [==============================] - 1s 517ms/step\n",
      "Epoch: 1, Batch: 18, Loss: [0.5031205415725708, 0.0]\n",
      "Predictions: [1 1]\n",
      "Epoch: 1, Batch: 19, Class Weights: {0: 0.6594059405940594, 1: 2.2751552795031054}\n",
      "1/1 [==============================] - 1s 515ms/step\n",
      "Epoch: 1, Batch: 19, Loss: [0.5206630229949951, 0.0]\n",
      "Predictions: [1 1]\n",
      "Epoch: 1, Batch: 20, Class Weights: {0: 0.6594059405940594, 1: 2.2751552795031054}\n",
      "1/1 [==============================] - 1s 516ms/step\n",
      "Epoch: 1, Batch: 20, Loss: [1.0270026922225952, 0.5]\n",
      "Predictions: [1 1]\n",
      "Epoch: 1, Batch: 21, Class Weights: {0: 0.6594059405940594, 1: 2.2751552795031054}\n",
      "1/1 [==============================] - 1s 524ms/step\n",
      "Epoch: 1, Batch: 21, Loss: [1.0804452896118164, 0.0]\n",
      "Predictions: [1 1]\n",
      "Epoch: 1, Batch: 22, Class Weights: {0: 0.6594059405940594, 1: 2.2751552795031054}\n",
      "1/1 [==============================] - 1s 532ms/step\n",
      "Epoch: 1, Batch: 22, Loss: [0.5626317858695984, 0.0]\n",
      "Predictions: [1 1]\n",
      "Epoch: 1, Batch: 23, Class Weights: {0: 0.6594059405940594, 1: 2.2751552795031054}\n",
      "1/1 [==============================] - 1s 554ms/step\n",
      "Epoch: 1, Batch: 23, Loss: [0.5322730541229248, 0.0]\n",
      "Predictions: [1 1]\n",
      "Epoch: 1, Batch: 24, Class Weights: {0: 0.6594059405940594, 1: 2.2751552795031054}\n",
      "1/1 [==============================] - 1s 547ms/step\n",
      "Epoch: 1, Batch: 24, Loss: [1.1086876392364502, 0.0]\n",
      "Predictions: [1 1]\n",
      "Epoch: 1, Batch: 25, Class Weights: {0: 0.6594059405940594, 1: 2.2751552795031054}\n",
      "1/1 [==============================] - 1s 529ms/step\n",
      "Epoch: 1, Batch: 25, Loss: [1.0815155506134033, 0.0]\n",
      "Predictions: [1 1]\n",
      "Epoch: 1, Batch: 26, Class Weights: {0: 0.6594059405940594, 1: 2.2751552795031054}\n",
      "1/1 [==============================] - 1s 527ms/step\n",
      "Epoch: 1, Batch: 26, Loss: [0.4501672685146332, 0.5]\n",
      "Predictions: [1 1]\n",
      "Epoch: 1, Batch: 27, Class Weights: {0: 0.6594059405940594, 1: 2.2751552795031054}\n",
      "1/1 [==============================] - 1s 534ms/step\n",
      "Epoch: 1, Batch: 27, Loss: [0.8893443942070007, 1.0]\n",
      "Predictions: [1 1]\n",
      "Epoch: 1, Batch: 28, Class Weights: {0: 0.6594059405940594, 1: 2.2751552795031054}\n",
      "1/1 [==============================] - 1s 528ms/step\n",
      "Epoch: 1, Batch: 28, Loss: [0.5673404932022095, 0.0]\n",
      "Predictions: [1 1]\n",
      "Epoch: 1, Batch: 29, Class Weights: {0: 0.6594059405940594, 1: 2.2751552795031054}\n",
      "1/1 [==============================] - 1s 518ms/step\n",
      "Epoch: 1, Batch: 29, Loss: [0.4830598831176758, 0.0]\n",
      "Predictions: [1 1]\n",
      "Epoch: 1, Batch: 30, Class Weights: {0: 0.6594059405940594, 1: 2.2751552795031054}\n",
      "1/1 [==============================] - 1s 525ms/step\n",
      "Epoch: 1, Batch: 30, Loss: [0.9311678409576416, 1.0]\n",
      "Predictions: [1 1]\n",
      "Epoch: 1, Batch: 31, Class Weights: {0: 0.6594059405940594, 1: 2.2751552795031054}\n",
      "1/1 [==============================] - 1s 527ms/step\n",
      "Epoch: 1, Batch: 31, Loss: [1.027732014656067, 0.5]\n",
      "Predictions: [1 1]\n",
      "Epoch: 1, Batch: 32, Class Weights: {0: 0.6594059405940594, 1: 2.2751552795031054}\n",
      "1/1 [==============================] - 1s 534ms/step\n",
      "Epoch: 1, Batch: 32, Loss: [0.46954864263534546, 0.0]\n",
      "Predictions: [1 1]\n",
      "Epoch: 1, Batch: 33, Class Weights: {0: 0.6594059405940594, 1: 2.2751552795031054}\n",
      "1/1 [==============================] - 1s 539ms/step\n",
      "Epoch: 1, Batch: 33, Loss: [0.9965033531188965, 0.5]\n",
      "Predictions: [1 1]\n",
      "Epoch: 1, Batch: 34, Class Weights: {0: 0.6594059405940594, 1: 2.2751552795031054}\n",
      "1/1 [==============================] - 1s 548ms/step\n",
      "Epoch: 1, Batch: 34, Loss: [0.5867024660110474, 0.0]\n",
      "Predictions: [1 1]\n",
      "Epoch: 1, Batch: 35, Class Weights: {0: 0.6594059405940594, 1: 2.2751552795031054}\n",
      "1/1 [==============================] - 1s 537ms/step\n",
      "Epoch: 1, Batch: 35, Loss: [0.5820028781890869, 0.0]\n",
      "Predictions: [1 1]\n",
      "Epoch: 1, Batch: 36, Class Weights: {0: 0.6594059405940594, 1: 2.2751552795031054}\n",
      "1/1 [==============================] - 1s 534ms/step\n",
      "Epoch: 1, Batch: 36, Loss: [0.5920096039772034, 0.0]\n",
      "Predictions: [1 1]\n",
      "Epoch: 1, Batch: 37, Class Weights: {0: 0.6594059405940594, 1: 2.2751552795031054}\n",
      "1/1 [==============================] - 1s 526ms/step\n",
      "Epoch: 1, Batch: 37, Loss: [0.5483053922653198, 0.0]\n",
      "Predictions: [1 1]\n",
      "Epoch: 1, Batch: 38, Class Weights: {0: 0.6594059405940594, 1: 2.2751552795031054}\n",
      "1/1 [==============================] - 1s 589ms/step\n",
      "Epoch: 1, Batch: 38, Loss: [0.8908761739730835, 0.5]\n",
      "Predictions: [1 1]\n",
      "Epoch: 1, Batch: 39, Class Weights: {0: 0.6594059405940594, 1: 2.2751552795031054}\n",
      "1/1 [==============================] - 1s 549ms/step\n",
      "Epoch: 1, Batch: 39, Loss: [1.0127447843551636, 0.5]\n",
      "Predictions: [1 1]\n",
      "Epoch: 1, Batch: 40, Class Weights: {0: 0.6594059405940594, 1: 2.2751552795031054}\n",
      "1/1 [==============================] - 1s 590ms/step\n",
      "Epoch: 1, Batch: 40, Loss: [0.9842093586921692, 1.0]\n",
      "Predictions: [1 1]\n",
      "Epoch: 1, Batch: 41, Class Weights: {0: 0.6594059405940594, 1: 2.2751552795031054}\n",
      "1/1 [==============================] - 1s 565ms/step\n",
      "Epoch: 1, Batch: 41, Loss: [0.48114705085754395, 0.5]\n",
      "Predictions: [1 1]\n",
      "Epoch: 1, Batch: 42, Class Weights: {0: 0.6594059405940594, 1: 2.2751552795031054}\n",
      "1/1 [==============================] - 1s 592ms/step\n",
      "Epoch: 1, Batch: 42, Loss: [0.534346342086792, 0.0]\n",
      "Predictions: [1 1]\n",
      "Epoch: 1, Batch: 43, Class Weights: {0: 0.6594059405940594, 1: 2.2751552795031054}\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range(0, len(input_ids), batch_size):\n",
    "        batch_input_ids = input_ids[i:i+batch_size]\n",
    "        batch_attention_mask = attention_mask[i:i+batch_size]\n",
    "        batch_labels = labels[i:i+batch_size]\n",
    "\n",
    "        # Calculate class weights for the current batch\n",
    "        batch_class_weights = {0: class_weight_dict[0], 1: class_weight_dict[1]}\n",
    "        print(f'Epoch: {epoch + 1}, Batch: {i // batch_size + 1}, Class Weights: {batch_class_weights}')\n",
    "\n",
    "        # Convert class weights to tensor\n",
    "        class_weights_tensor = tf.convert_to_tensor(list(batch_class_weights.values()), dtype=tf.float32)\n",
    "\n",
    "        # Train the model on the current batch using train_on_batch\n",
    "        weighted_loss = model.train_on_batch([batch_input_ids, batch_attention_mask], batch_labels, class_weight=batch_class_weights)\n",
    "\n",
    "        # Get model predictions\n",
    "        output = model.predict([batch_input_ids, batch_attention_mask])\n",
    "        logits = output.logits  # Extract logits from TFSequenceClassifierOutput\n",
    "        predicted_labels = tf.argmax(tf.nn.softmax(logits), axis=-1).numpy()\n",
    "\n",
    "        # Print metrics or log them as needed\n",
    "        print(f'Epoch: {epoch + 1}, Batch: {i // batch_size + 1}, Loss: {weighted_loss}')\n",
    "        print(f'Predictions: {predicted_labels}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "id": "ieTxsOHsFEX9",
    "outputId": "207fb4d5-c723-4756-d640-4df95661dffe"
   },
   "outputs": [],
   "source": [
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# model.fit(\n",
    "#     {'input_ids': input_ids, 'attention_mask': attention_mask},\n",
    "#     {'labels': labels},  # Assuming your labels are named 'labels'\n",
    "#     epochs=1,\n",
    "#     batch_size=2,\n",
    "#     class_weight=class_weight_dict\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cyRbtQpVFQ8A"
   },
   "outputs": [],
   "source": [
    "df1=pd.read_csv('dev31.csv')\n",
    "df1.fillna(' ',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 851
    },
    "id": "ltSk6iESMbjX",
    "outputId": "33b964a8-1015-48e8-c2f0-d369efcc4996"
   },
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L-PIOfknMdi4"
   },
   "outputs": [],
   "source": [
    "test_text=[]\n",
    "test_labels=[]\n",
    "for i in range(len(df1)):\n",
    "  temp=df1['question'][i]+df1['answer'][i]+df1['expl'][i]\n",
    "  test_text.append(temp)\n",
    "  test_labels.append(df['label'][i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m6km3WwYO-y1"
   },
   "outputs": [],
   "source": [
    "tokenized_test = tokenizer(test_text, return_tensors=\"tf\", padding=True, truncation=True)\n",
    "test_input_ids = tokenized_test['input_ids']\n",
    "test_attention_mask = tokenized_test['attention_mask']\n",
    "test_labels=np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C3Z8Kr2IMzIc",
    "outputId": "e7f5266d-b663-4075-a6ac-3c8105a1ede6"
   },
   "outputs": [],
   "source": [
    "eval_result = model.evaluate(\n",
    "    {'input_ids': test_input_ids, 'attention_mask': test_attention_mask},\n",
    "    test_labels\n",
    ")\n",
    "print(\"Test Accuracy:\", eval_result[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "id": "j19xTd7aOeri",
    "outputId": "61fa327f-b71c-4aad-a952-08eb81621f96"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(\n",
    "    {'input_ids': test_input_ids, 'attention_mask': test_attention_mask},\n",
    "    verbose=0\n",
    ")\n",
    "# predicted_labels = np.argmax(predictions, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dJYs9QhHQGwA",
    "outputId": "2a3930e1-ff4b-4c31-9120-0a35638e7fd6"
   },
   "outputs": [],
   "source": [
    "predictions_np = np.array(predictions.logits)\n",
    "\n",
    "# Check the shape\n",
    "print(\"Shape of predictions array:\", predictions_np.shape)\n",
    "\n",
    "# Get the predicted labels\n",
    "predicted_labels = np.argmax(predictions_np, axis=1)\n",
    "\n",
    "# Print the predicted labels\n",
    "print(\"Predicted Labels:\", predicted_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ixe1_vdFPt5V",
    "outputId": "e76c07ba-5298-47af-e351-63aa1b2bc573"
   },
   "outputs": [],
   "source": [
    "print(\"Predicted Labels:\", predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fgwPMFFQRa33"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
